DEFINATION OF LINEAR REGRESSION ----

--> Linear regression is a statistical method that models the relationship between two variables by fitting a linear equation to observed data. 
--> One variable is considered an independent variable, and the other is the dependent variable.


--> The simplest form of the linear equation with one dependent and one independent variable is represented by:

                               y=mx+c


Where:

y is the dependent variable.
x is the independent variable.
m is the slope of the line.
c is the y-intercept.





GOAL OF LINEAR REGRESSION ----

--> The main goal of linear regression is to find the best fit straight line that accurately predict the output values within a range.






Function of Linear Regression:
Let's express the relationship in a more generalized way:

                     y=β0​+β1​x1​+ϵ


Where:

y is the dependent variable.
x1 is the independent variable.
β0 is the y-intercept. It represents the value of y when x1=0
β1 is the slope. It represents the change in y for a one-unit change in x1
ϵ is the error term (observed value - predicted value).





DETERMNATION OF BEST FIT LINE ---

--> The best-fit line is determined using a method called the LEAST SQUARE technique.
--> The idea is to find the line that minimizes the sum of the squared differences (errors) between the observed values (actual data points) and the values predicted by the model.






APPLICATIONS OF LINEAR REGRESSION ---

1. Forecasting
2. Stock Price Prediction
3. Customer Analysis
4. Climate Modeling
5. Performance Prediction


